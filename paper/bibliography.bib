@inproceedings{speer2017conceptnet,
  title     = {Conceptnet 5.5: An open multilingual graph of general knowledge},
  author    = {Speer, Robyn and Chin, Joshua and Havasi, Catherine},
  booktitle = {Proceedings of the AAAI conference on artificial intelligence},
  volume    = {31},
  number    = {1},
  year      = {2017}
}

@article{Kriegeskorte2008,
  title     = {Representational similarity analysis – connecting the branches of systems neuroscience},
  issn      = {1662-5137},
  url       = {http://dx.doi.org/10.3389/neuro.06.004.2008},
  doi       = {10.3389/neuro.06.004.2008},
  journal   = {Frontiers in Systems Neuroscience},
  publisher = {Frontiers Media SA},
  author    = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter},
  year      = {2008}
}

@article{Spearman1904,
  title     = {The Proof and Measurement of Association between Two Things},
  volume    = {15},
  issn      = {0002-9556},
  url       = {http://dx.doi.org/10.2307/1412159},
  doi       = {10.2307/1412159},
  number    = {1},
  journal   = {The American Journal of Psychology},
  publisher = {University of Illinois Press},
  author    = {Spearman,  C.},
  year      = {1904},
  month     = jan,
  pages     = {72}
}

@article{Cohen1960,
  title     = {A Coefficient of Agreement for Nominal Scales},
  volume    = {20},
  issn      = {1552-3888},
  url       = {http://dx.doi.org/10.1177/001316446002000104},
  doi       = {10.1177/001316446002000104},
  number    = {1},
  journal   = {Educational and Psychological Measurement},
  publisher = {SAGE Publications},
  author    = {Cohen,  Jacob},
  year      = {1960},
  month     = apr,
  pages     = {37–46}
}

@article{Artstein2008,
  title     = {Inter-Coder Agreement for Computational Linguistics},
  volume    = {34},
  issn      = {1530-9312},
  url       = {http://dx.doi.org/10.1162/coli.07-034-R2},
  doi       = {10.1162/coli.07-034-r2},
  number    = {4},
  journal   = {Computational Linguistics},
  publisher = {MIT Press - Journals},
  author    = {Artstein,  Ron and Poesio,  Massimo},
  year      = {2008},
  month     = dec,
  pages     = {555–596}
}

@misc{https://doi.org/10.48550/arxiv.1802.03426,
  doi       = {10.48550/ARXIV.1802.03426},
  url       = {https://arxiv.org/abs/1802.03426},
  author    = {McInnes,  Leland and Healy,  John and Melville,  James},
  keywords  = {Machine Learning (stat.ML),  Computational Geometry (cs.CG),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title     = {UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@article{Kriegeskorte2013,
  title     = {Representational geometry: integrating cognition,  computation,  and the brain},
  volume    = {17},
  issn      = {1364-6613},
  url       = {http://dx.doi.org/10.1016/j.tics.2013.06.007},
  doi       = {10.1016/j.tics.2013.06.007},
  number    = {8},
  journal   = {Trends in Cognitive Sciences},
  publisher = {Elsevier BV},
  author    = {Kriegeskorte,  Nikolaus and Kievit,  Rogier A.},
  year      = {2013},
  month     = aug,
  pages     = {401–412}
}

@article{Gentner1983,
  title     = {Structure-mapping: A theoretical framework for analogy},
  volume    = {7},
  issn      = {0364-0213},
  url       = {http://dx.doi.org/10.1016/S0364-0213(83)80009-3},
  doi       = {10.1016/s0364-0213(83)80009-3},
  number    = {2},
  journal   = {Cognitive Science},
  publisher = {Wiley},
  author    = {Gentner,  D},
  year      = {1983},
  month     = jun,
  pages     = {155–170}
}

@article{Fodor1988,
  title     = {Connectionism and cognitive architecture: A critical analysis},
  volume    = {28},
  issn      = {0010-0277},
  url       = {http://dx.doi.org/10.1016/0010-0277(88)90031-5},
  doi       = {10.1016/0010-0277(88)90031-5},
  number    = {1–2},
  journal   = {Cognition},
  publisher = {Elsevier BV},
  author    = {Fodor,  Jerry A. and Pylyshyn,  Zenon W.},
  year      = {1988},
  month     = mar,
  pages     = {3–71}
}

@inproceedings{McCoy2019,
  title     = {Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference},
  author    = {McCoy, R. Thomas  and
               Pavlick, Ellie  and
               Linzen, Tal},
  editor    = {Korhonen, Anna  and
               Traum, David  and
               M{\`a}rquez, Llu{\'i}s},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P19-1334/},
  doi       = {10.18653/v1/P19-1334},
  pages     = {3428--3448},
  abstract  = {A machine learning system can score well on a given test set by relying on heuristics that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. To determine whether models have adopted these heuristics, we introduce a controlled evaluation set called HANS (Heuristic Analysis for NLI Systems), which contains many examples where the heuristics fail. We find that models trained on MNLI, including BERT, a state-of-the-art model, perform very poorly on HANS, suggesting that they have indeed adopted these heuristics. We conclude that there is substantial room for improvement in NLI systems, and that the HANS dataset can motivate and measure progress in this area.}
}

@inproceedings{Niven2019,
  title     = {Probing Neural Network Comprehension of Natural Language Arguments},
  author    = {Niven, Timothy  and
               Kao, Hung-Yu},
  editor    = {Korhonen, Anna  and
               Traum, David  and
               M{\`a}rquez, Llu{\'i}s},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P19-1459/},
  doi       = {10.18653/v1/P19-1459},
  pages     = {4658--4664},
  abstract  = {We are surprised to find that BERT`s peak performance of 77{\%} on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.}
}

@inproceedings{Bender2020,
  title     = {Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data},
  author    = {Bender, Emily M.  and
               Koller, Alexander},
  editor    = {Jurafsky, Dan  and
               Chai, Joyce  and
               Schluter, Natalie  and
               Tetreault, Joel},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-main.463/},
  doi       = {10.18653/v1/2020.acl-main.463},
  pages     = {5185--5198},
  abstract  = {The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as {\textquotedblleft}understanding{\textquotedblright} language or capturing {\textquotedblleft}meaning{\textquotedblright}. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of {\textquotedblleft}Taking Stock of Where We`ve Been and Where We`re Going{\textquotedblright}, we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.}
}

@incollection{gentner2005relational,
  author    = {Dedre Gentner and Kenneth J. Kurtz},
  title     = {Relational Categories},
  booktitle = {Categorization Inside and Outside the Laboratory: Essays in Honor of Douglas L. Medin},
  editor    = {W. K. Ahn and R. L. Goldstone and B. C. Love and A. B. Markman and P. Wolff},
  pages     = {151--175},
  publisher = {American Psychological Association},
  year      = {2005},
  doi       = {10.1037/11156-009}
}


@article{Kaufer1979,
  title     = {The Competence/Performance Distinction in Linguistic Theory},
  volume    = {9},
  issn      = {1552-7441},
  url       = {http://dx.doi.org/10.1177/004839317900900301},
  doi       = {10.1177/004839317900900301},
  number    = {3},
  journal   = {Philosophy of the Social Sciences},
  publisher = {SAGE Publications},
  author    = {Kaufer,  David S.},
  year      = {1979},
  month     = sep,
  pages     = {257–275}
}

@book{Chomsky1965,
  title     = {Aspects of the theory of syntax},
  author    = {Chomsky, Noam},
  publisher = {MIT Press},
  month     = jan,
  year      = 1965,
  address   = {London, England}
}

@article{davis2015commonsense,
  title     = {Commonsense reasoning and commonsense knowledge in artificial intelligence},
  author    = {Davis, Ernest and Marcus, Gary},
  journal   = {Communications of the ACM},
  volume    = {58},
  number    = {9},
  pages     = {92--103},
  year      = {2015},
  publisher = {ACM New York, NY, USA}
}

@book{cattell1971abilities,
  title     = {Abilities: Their Structure, Growth, and Action},
  author    = {Cattell, R.B.},
  isbn      = {9780395042755},
  lccn      = {lc77143324},
  url       = {https://books.google.com/books?id=9dRq2P9SI5QC},
  year      = {1971},
  publisher = {Houghton Mifflin}
}

@inproceedings{liu-etal-2019-linguistic,
  title     = {Linguistic Knowledge and Transferability of Contextual Representations},
  author    = {Liu, Nelson F.  and
               Gardner, Matt  and
               Belinkov, Yonatan  and
               Peters, Matthew E.  and
               Smith, Noah A.},
  editor    = {Burstein, Jill  and
               Doran, Christy  and
               Solorio, Thamar},
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  month     = jun,
  year      = {2019},
  address   = {Minneapolis, Minnesota},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/N19-1112/},
  doi       = {10.18653/v1/N19-1112},
  pages     = {1073--1094},
  abstract  = {Contextual word representations derived from large-scale neural language models are successful across a diverse set of NLP tasks, suggesting that they encode useful and transferable features of language. To shed light on the linguistic knowledge they capture, we study the representations produced by several recent pretrained contextualizers (variants of ELMo, the OpenAI transformer language model, and BERT) with a suite of sixteen diverse probing tasks. We find that linear models trained on top of frozen contextual representations are competitive with state-of-the-art task-specific models in many cases, but fail on tasks requiring fine-grained linguistic knowledge (e.g., conjunct identification). To investigate the transferability of contextual word representations, we quantify differences in the transferability of individual layers within contextualizers, especially between recurrent neural networks (RNNs) and transformers. For instance, higher layers of RNNs are more task-specific, while transformer layers do not exhibit the same monotonic trend. In addition, to better understand what makes contextual word representations transferable, we compare language model pretraining with eleven supervised pretraining tasks. For any given task, pretraining on a closely related task yields better performance than language model pretraining (which is better on average) when the pretraining dataset is fixed. However, language model pretraining on more data gives the best results.}
}

@inproceedings{tenney-etal-2019-bert,
  title     = {{BERT} Rediscovers the Classical {NLP} Pipeline},
  author    = {Tenney, Ian  and
               Das, Dipanjan  and
               Pavlick, Ellie},
  editor    = {Korhonen, Anna  and
               Traum, David  and
               M{\`a}rquez, Llu{\'i}s},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2019},
  address   = {Florence, Italy},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P19-1452/},
  doi       = {10.18653/v1/P19-1452},
  pages     = {4593--4601},
  abstract  = {Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.}
}

@misc{gandikota2024evolution,
  title  = {Evolution of LLM Stages across Model Sizes},
  author = {Rohit Gandikota and Alex Loftus and Philip and Ritik Bompilwar and Can Rager},
  year   = {2024},
  month  = dec,
  note   = {Unpublished manuscript},
  url    = {https://sidn.baulab.info/evolution/}
}

@article{Laakso2000,
  title     = {Content and cluster analysis: Assessing representational similarity in neural systems},
  volume    = {13},
  issn      = {1465-394X},
  url       = {http://dx.doi.org/10.1080/09515080050002726},
  doi       = {10.1080/09515080050002726},
  number    = {1},
  journal   = {Philosophical Psychology},
  publisher = {Informa UK Limited},
  author    = {Laakso,  Aarre and Cottrell,  Garrison},
  year      = {2000},
  month     = mar,
  pages     = {47–76}
}

@inproceedings{devlin-etal-2019-bert,
  title     = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author    = {Devlin, Jacob  and
               Chang, Ming-Wei  and
               Lee, Kenton  and
               Toutanova, Kristina},
  editor    = {Burstein, Jill  and
               Doran, Christy  and
               Solorio, Thamar},
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  month     = jun,
  year      = {2019},
  address   = {Minneapolis, Minnesota},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/N19-1423/},
  doi       = {10.18653/v1/N19-1423},
  pages     = {4171--4186},
  abstract  = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).}
}

@article{Gawin2025,
  title        = {Navigating semantic relations: Challenges for language models
                  in abstract common-sense reasoning},
  author       = {Gawin, Cole and Sun, Yidan and Kejriwal, Mayank},
  year         = 2025,
  primaryclass = {cs.CL},
  eprint       = {2502.14086}
}

@inproceedings{Mikolov2013,
  author    = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Distributed Representations of Words and Phrases and their Compositionality},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf},
  volume    = {26},
  year      = {2013}
}

@inproceedings{ethayarajh-2019-contextual,
  title     = {How Contextual are Contextualized Word Representations? {C}omparing the Geometry of {BERT}, {ELM}o, and {GPT}-2 Embeddings},
  author    = {Ethayarajh, Kawin},
  editor    = {Inui, Kentaro  and
               Jiang, Jing  and
               Ng, Vincent  and
               Wan, Xiaojun},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  month     = nov,
  year      = {2019},
  address   = {Hong Kong, China},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D19-1006/},
  doi       = {10.18653/v1/D19-1006},
  pages     = {55--65},
  abstract  = {Replacing static word embeddings with contextualized word representations has yielded significant improvements on many NLP tasks. However, just how contextual are the contextualized representations produced by models such as ELMo and BERT? Are there infinitely many context-specific representations for each word, or are words essentially assigned one of a finite number of word-sense representations? For one, we find that the contextualized representations of all words are not isotropic in any layer of the contextualizing model. While representations of the same word in different contexts still have a greater cosine similarity than those of two different words, this self-similarity is much lower in upper layers. This suggests that upper layers of contextualizing models produce more context-specific representations, much like how upper layers of LSTMs produce more task-specific representations. In all layers of ELMo, BERT, and GPT-2, on average, less than 5{\%} of the variance in a word`s contextualized representations can be explained by a static embedding for that word, providing some justification for the success of contextualized representations.}
}

@inproceedings{merchant-etal-2020-happens,
  title     = {What Happens To {BERT} Embeddings During Fine-tuning?},
  author    = {Merchant, Amil  and
               Rahimtoroghi, Elahe  and
               Pavlick, Ellie  and
               Tenney, Ian},
  editor    = {Alishahi, Afra  and
               Belinkov, Yonatan  and
               Chrupa{\l}a, Grzegorz  and
               Hupkes, Dieuwke  and
               Pinter, Yuval  and
               Sajjad, Hassan},
  booktitle = {Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.blackboxnlp-1.4/},
  doi       = {10.18653/v1/2020.blackboxnlp-1.4},
  pages     = {33--44},
  abstract  = {While much recent work has examined how linguistic information is encoded in pre-trained sentence representations, comparatively little is understood about how these models change when adapted to solve downstream tasks. Using a suite of analysis techniques{---}supervised probing, unsupervised similarity analysis, and layer-based ablations{---}we investigate how fine-tuning affects the representations of the BERT model. We find that while fine-tuning necessarily makes some significant changes, there is no catastrophic forgetting of linguistic phenomena. We instead find that fine-tuning is a conservative process that primarily affects the top layers of BERT, albeit with noteworthy variation across tasks. In particular, dependency parsing reconfigures most of the model, whereas SQuAD and MNLI involve much shallower processing. Finally, we also find that fine-tuning has a weaker effect on representations of out-of-domain sentences, suggesting room for improvement in model generalization.}
}

@article{Lake2017,
  title   = {Building machines that learn and think like people},
  volume  = {40},
  doi     = {10.1017/S0140525X16001837},
  journal = {Behavioral and Brain Sciences},
  author  = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  year    = {2017},
  pages   = {e253}
}
@misc{https://doi.org/10.48550/arxiv.2302.13971,
  doi       = {10.48550/ARXIV.2302.13971},
  url       = {https://arxiv.org/abs/2302.13971},
  author    = {Touvron,  Hugo and Lavril,  Thibaut and Izacard,  Gautier and Martinet,  Xavier and Lachaux,  Marie-Anne and Lacroix,  Timothée and Rozière,  Baptiste and Goyal,  Naman and Hambro,  Eric and Azhar,  Faisal and Rodriguez,  Aurelien and Joulin,  Armand and Grave,  Edouard and Lample,  Guillaume},
  keywords  = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title     = {LLaMA: Open and Efficient Foundation Language Models},
  publisher = {arXiv},
  year      = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{gemmateam2024gemmaopenmodelsbased,
  title         = {Gemma: Open Models Based on Gemini Research and Technology},
  author        = {{Gemma Team}},
  year          = {2024},
  eprint        = {2403.08295},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2403.08295}
}

@misc{https://doi.org/10.48550/arxiv.2408.00690,
  doi       = {10.48550/ARXIV.2408.00690},
  url       = {https://arxiv.org/abs/2408.00690},
  author    = {Ukarapol,  Trapoom and Lee,  Zhicheng and Xin,  Amy},
  keywords  = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title     = {Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning},
  publisher = {arXiv},
  year      = {2024},
  copyright = {Creative Commons Attribution 4.0 International}
}